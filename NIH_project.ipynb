{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Cw48i_eju2vBsZpDGRUmJ7MB6pJGh5_0",
      "authorship_tag": "ABX9TyPP3/6E8KrgiFVtvcfwnF9k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toinnn/Torax_Xray-Health-Care/blob/main/NIH_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLzQzBHuHA0J",
        "outputId": "2930cef2-419b-4c51-ecf5-48990918baff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Obtém o número de núcleos da CPU\n",
        "num_cores = os.cpu_count()\n",
        "\n",
        "# Obtém informações sobre a CPU\n",
        "cpu_info = !lscpu\n",
        "\n",
        "# Imprime o número de núcleos e informações sobre a CPU\n",
        "print(f\"Número de núcleos da CPU: {num_cores}\")\n",
        "# print(\"Informações sobre a CPU:\")\n",
        "# for line in cpu_info:\n",
        "#     print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RusLtc5u4zyz",
        "outputId": "943b08ed-4e58-4e45-aca8-4c5fc899b4b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de núcleos da CPU: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Git_Dir    = \"/content/drive/MyDrive/Github_Dir/Torax_Xray-Health-Care\" #https://github.com/toinnn/Torax_Xray-Health-Care\n",
        "Neural_Dir = \"Torax_Xray-Health-Care\"\n",
        "with open(\"/content/drive/MyDrive/Github_Dir/acess_Token_Git.txt\",\"r\") as file:\n",
        "    acess_Token_Git = file.read()\n",
        "Git_Path   = \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + Neural_Dir + \".git\"\n",
        "# Git_CB_Path= \"https://\"+ acess_Token_Git + \"@github.com/toinnn/\" + \"Chat_Bot\" + \".git\""
      ],
      "metadata": {
        "id": "hGjEYWH-WQFY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"{Git_Path}\" ./temp/Torax_Xray-Health-Care\n",
        "# !git clone \"{Git_CB_Path}\" ./temp/Chat_Bot\n",
        "\n",
        "!mv ./temp/* \"{Git_Dir}\"\n",
        "!rm -rf ./temp\n",
        "\n",
        "!rsync -aP \"{Git_Dir}\"/*  ./\n",
        "# #!ln -s \"/content/drive/MyDrive/Github_Dir/Chat_Bot\" + Neural_Dir NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L25_RTrWadA",
        "outputId": "8c324e15-def6-4403-aef0-4b40a2b4d919"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './temp/Torax_Xray-Health-Care'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 101 (delta 58), reused 67 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (101/101), 51.26 KiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "mv: inter-device move failed: './temp/Torax_Xray-Health-Care' to '/content/drive/MyDrive/Github_Dir/Torax_Xray-Health-Care/Torax_Xray-Health-Care'; unable to remove target: Directory not empty\n",
            "sending incremental file list\n",
            "Torax_Xray-Health-Care/\n",
            "Torax_Xray-Health-Care/.gitattributes\n",
            "             66 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=52/54)\n",
            "Torax_Xray-Health-Care/.gitignore\n",
            "             27 100%    0.08kB/s    0:00:00 (xfr#2, to-chk=51/54)\n",
            "Torax_Xray-Health-Care/DinoV2.py\n",
            "         11,283 100%   13.52kB/s    0:00:00 (xfr#3, to-chk=50/54)\n",
            "Torax_Xray-Health-Care/LICENSE\n",
            "          1,063 100%    0.83kB/s    0:00:01 (xfr#4, to-chk=49/54)\n",
            "Torax_Xray-Health-Care/NIH_project.ipynb\n",
            "        247,451 100%  204.74MB/s    0:00:00 (xfr#5, to-chk=48/54)\n",
            "Torax_Xray-Health-Care/Transformer_Decoder.py\n",
            "         37,105 100%   85.46kB/s    0:00:00 (xfr#6, to-chk=47/54)\n",
            "Torax_Xray-Health-Care/.git/\n",
            "Torax_Xray-Health-Care/.git/HEAD\n",
            "             21 100%    0.03kB/s    0:00:00 (xfr#7, to-chk=44/54)\n",
            "Torax_Xray-Health-Care/.git/config\n",
            "            314 100%    0.22kB/s    0:00:01 (xfr#8, to-chk=43/54)\n",
            "Torax_Xray-Health-Care/.git/description\n",
            "             73 100%    0.00kB/s    0:00:00 (xfr#9, to-chk=42/54)\n",
            "Torax_Xray-Health-Care/.git/index\n",
            "            773 100%    1.65kB/s    0:00:00 (xfr#10, to-chk=41/54)\n",
            "Torax_Xray-Health-Care/.git/packed-refs\n",
            "            112 100%    0.11kB/s    0:00:01 (xfr#11, to-chk=40/54)\n",
            "Torax_Xray-Health-Care/.git/branches/\n",
            "Torax_Xray-Health-Care/.git/hooks/\n",
            "Torax_Xray-Health-Care/.git/hooks/applypatch-msg.sample\n",
            "            478 100%    0.35kB/s    0:00:01 (xfr#12, to-chk=33/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/commit-msg.sample\n",
            "            896 100%    0.00kB/s    0:00:00 (xfr#13, to-chk=32/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/fsmonitor-watchman.sample\n",
            "          4,655 100%   12.03kB/s    0:00:00 (xfr#14, to-chk=31/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/post-update.sample\n",
            "            189 100%    0.27kB/s    0:00:00 (xfr#15, to-chk=30/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/pre-applypatch.sample\n",
            "            424 100%    0.42kB/s    0:00:00 (xfr#16, to-chk=29/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/pre-commit.sample\n",
            "          1,643 100%    1.24kB/s    0:00:01 (xfr#17, to-chk=28/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/pre-merge-commit.sample\n",
            "            416 100%    0.00kB/s    0:00:00 (xfr#18, to-chk=27/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/pre-push.sample\n",
            "          1,374 100%    4.08kB/s    0:00:00 (xfr#19, to-chk=26/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/pre-rebase.sample\n",
            "          4,898 100%    7.53kB/s    0:00:00 (xfr#20, to-chk=25/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/pre-receive.sample\n",
            "            544 100%    0.55kB/s    0:00:00 (xfr#21, to-chk=24/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/prepare-commit-msg.sample\n",
            "          1,492 100%    1.03kB/s    0:00:01 (xfr#22, to-chk=23/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/push-to-checkout.sample\n",
            "          2,783 100%    0.00kB/s    0:00:00 (xfr#23, to-chk=22/54)\n",
            "Torax_Xray-Health-Care/.git/hooks/update.sample\n",
            "          3,650 100%   10.90kB/s    0:00:00 (xfr#24, to-chk=21/54)\n",
            "Torax_Xray-Health-Care/.git/info/\n",
            "Torax_Xray-Health-Care/.git/info/exclude\n",
            "            240 100%    0.36kB/s    0:00:00 (xfr#25, to-chk=20/54)\n",
            "Torax_Xray-Health-Care/.git/logs/\n",
            "Torax_Xray-Health-Care/.git/logs/HEAD\n",
            "            196 100%    0.18kB/s    0:00:01 (xfr#26, to-chk=19/54)\n",
            "Torax_Xray-Health-Care/.git/logs/refs/\n",
            "Torax_Xray-Health-Care/.git/logs/refs/heads/\n",
            "Torax_Xray-Health-Care/.git/logs/refs/heads/main\n",
            "            196 100%    0.14kB/s    0:00:01 (xfr#27, to-chk=15/54)\n",
            "Torax_Xray-Health-Care/.git/logs/refs/remotes/\n",
            "Torax_Xray-Health-Care/.git/logs/refs/remotes/origin/\n",
            "Torax_Xray-Health-Care/.git/logs/refs/remotes/origin/HEAD\n",
            "            196 100%    0.00kB/s    0:00:00 (xfr#28, to-chk=13/54)\n",
            "Torax_Xray-Health-Care/.git/objects/\n",
            "Torax_Xray-Health-Care/.git/objects/info/\n",
            "Torax_Xray-Health-Care/.git/objects/pack/\n",
            "Torax_Xray-Health-Care/.git/objects/pack/pack-84174de103bf8ce439ebc8a0580ecbb3d0278911.idx\n",
            "          3,900 100%   10.58kB/s    0:00:00 (xfr#29, to-chk=10/54)\n",
            "Torax_Xray-Health-Care/.git/objects/pack/pack-84174de103bf8ce439ebc8a0580ecbb3d0278911.pack\n",
            "         52,487 100%   75.60kB/s    0:00:00 (xfr#30, to-chk=9/54)\n",
            "Torax_Xray-Health-Care/.git/refs/\n",
            "Torax_Xray-Health-Care/.git/refs/heads/\n",
            "Torax_Xray-Health-Care/.git/refs/heads/main\n",
            "             41 100%    0.04kB/s    0:00:01 (xfr#31, to-chk=5/54)\n",
            "Torax_Xray-Health-Care/.git/refs/remotes/\n",
            "Torax_Xray-Health-Care/.git/refs/remotes/origin/\n",
            "Torax_Xray-Health-Care/.git/refs/remotes/origin/HEAD\n",
            "             30 100%    0.02kB/s    0:00:01 (xfr#32, to-chk=3/54)\n",
            "Torax_Xray-Health-Care/.git/refs/tags/\n",
            "Torax_Xray-Health-Care/web_app/\n",
            "Torax_Xray-Health-Care/web_app/index.html\n",
            "            613 100%    0.00kB/s    0:00:00 (xfr#33, to-chk=2/54)\n",
            "Torax_Xray-Health-Care/web_app/css/\n",
            "Torax_Xray-Health-Care/web_app/css/style.css\n",
            "            212 100%    0.62kB/s    0:00:00 (xfr#34, to-chk=0/54)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/{Neural_Dir}\"\n",
        "# %cd \"/content/drive/MyDrive/Github_Dir/Torax_Xray-Health-Care\"\n",
        "\n",
        "# %cd /content/Chat_Bot"
      ],
      "metadata": {
        "id": "IJalNV5aW1u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a28626-27b9-456a-af2f-77fd42efec9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Torax_Xray-Health-Care\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def image_i_path(id):\n",
        "    if id <= 4999 :\n",
        "        i = 1\n",
        "    elif id <=  14999 :\n",
        "        i = 2\n",
        "    elif id <=  24999 :\n",
        "        i = 3\n",
        "    elif id <=  34999 :#24999 + 10000:\n",
        "        i = 4\n",
        "    elif id <=  44999 : #24999 + 9829:\n",
        "        i = 5\n",
        "    elif id <=  54999 : #24999 + 9829:\n",
        "        i = 6\n",
        "    elif id <=  64999 : #24999 + 9829:\n",
        "        i = 7\n",
        "    elif id <=  74999 : #24999 + 9829:\n",
        "        i = 8\n",
        "    elif id <=  84999 : #24999 + 9829:\n",
        "        i = 9\n",
        "    elif id <=  94999 : #24999 + 9829:\n",
        "        i = 10\n",
        "    elif id <= 104999 : #24999 + 9829:\n",
        "        i = 11\n",
        "    elif id <= 104999 + 7121 : #24999 + 9829:\n",
        "        i = 12\n",
        "    if i < 10 :\n",
        "      return  f\"/content/drive/MyDrive/X-ray_2/Dataset/images_00{i}/images\"\n",
        "    else :\n",
        "      return  f\"/content/drive/MyDrive/X-ray_2/Dataset/images_0{i}/images\""
      ],
      "metadata": {
        "id": "vowbpNzzV4ZL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Transformer_Decoder import decoder , Trainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# from Transformer_Decoder import decoder , Trainer\n",
        "from torch.utils.data import DataLoader , Dataset\n",
        "import json\n",
        "# from torchvision.io.image import decode_png, read_image\n",
        "from torchvision.io import decode_png, read_image , ImageReadMode\n",
        "import torchvision.transforms as T\n",
        "import polars as pl\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "def load_image_nvjpngl_gpu(image_path):\n",
        "    \"\"\"\n",
        "    Loads an image from the specified file path using NVJPEG decoder on GPU and returns a PyTorch tensor.\n",
        "    Args:\n",
        "        image_path (str): The path to the image file.\n",
        "    Returns:\n",
        "        torch.Tensor: The PyTorch tensor representing the image.\n",
        "    \"\"\"\n",
        "    data = read_image(image_path , mode = ImageReadMode.GRAY )\n",
        "    return data.float()\n",
        "    # print(data)\n",
        "    tensor = decode_png(data).float()#.to(\"cuda\")\n",
        "    return tensor\n",
        "\n",
        "class dataset_NIH_Chest(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, list_IDs : list[str] , Data_Entry_path : str , image_dir_path : str , label2class_path : str , max_label_lengh : int ):\n",
        "        'Initialization'\n",
        "        # self.labels = labels\n",
        "        self.list_IDs = tuple(list_IDs) #Lista contendo os nomes das imagens\n",
        "        self.image_dir_path = image_dir_path #string com o path da pasta que contem as imagens de input\n",
        "        self.Data_Entry  = pl.read_csv(Data_Entry_path)\n",
        "        self.label2class = json.load(open(label2class_path , \"rb\"))\n",
        "        self.y_len_max = max_label_lengh + 1\n",
        "        # for row in data_intro[['Image Index' ,'Finding Labels' ]].iter_rows(named=True) :\n",
        "        #     print({row['Image Index'] : row['Finding Labels'].split(\"|\") })\n",
        "        #     raise\n",
        "        self.Data_Entry = {row['Image Index'] : row['Finding Labels'].split(\"|\") for row in self.Data_Entry[['Image Index' ,'Finding Labels' ]].iter_rows(named=True)}\n",
        "        \"\"\"for row in data_intro[['Image Index' ,'Finding Labels' ]].iter_rows(named=True) :\n",
        "            if max_label_lengh < len( row['Finding Labels'].split(\"|\")  )  : \"\"\"\n",
        "        # keys = tuple(self.Data_Entry.keys())\n",
        "        # self.name_2_index = { keys[i] : i+1  for i in range(len(keys)) }\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID = self.list_IDs[index]\n",
        "        # linha_encontrada = self.Data_Entry.filter(( self.Data_Entry['Image Index'] == self.list_IDs[index] ) )\n",
        "        # linha_encontrada['Finding Labels'].split(\"|\")\n",
        "\n",
        "        y = torch.tensor([ int(self.label2class[i]) for i in self.Data_Entry[ID]] ).view(-1, 1) #linha_encontrada['Finding Labels'][0].split(\"|\") ]).view(-1, 1)\n",
        "\n",
        "        # aux = self.y_len_max - y.shape[0]\n",
        "        # if aux != 0 :\n",
        "        aux = torch.zeros( self.y_len_max - y.shape[0]  , 1)\n",
        "        y = torch.cat([y , aux] , dim = 0)\n",
        "\n",
        "        # Load data and get label\n",
        "        X = load_image_nvjpngl_gpu(self.image_dir_path + self.list_IDs[index]) #torch.load( self.image_dir_path + self.list_IDs[index] )\n",
        "\n",
        "\n",
        "        # path = image_i_path( self.name_2_index[ID] ) + \"/\" + ID\n",
        "        # X = load_image_nvjpngl_gpu(path)\n",
        "\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "class my_model(nn.Module):\n",
        "    def __init__(self ,  device : torch.device = torch.device(\"cpu\")) -> None:\n",
        "        super(my_model , self  ).__init__()\n",
        "        vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')\n",
        "        # vits14.eval()\n",
        "        # print(vits14.eval())\n",
        "        self.encoder = vits14.to(device) #EU NÃO LEMBRO QUANTO DEVERIA SER O MODEL_DIM !!!!!\n",
        "        self.decoder = decoder(model_dim = 768 ,heads = 8 ,num_layers = 8 , num_Classes = 16 , device = device)\n",
        "        self.device  = device\n",
        "        # self.transform_image = T.Compose([T.Resize(244), T.CenterCrop(224), T.Normalize([0.5], [0.5])] )\n",
        "        self.transform_image = T.Compose([T.Resize(224),  T.Normalize([0.5], [0.5])] )\n",
        "\n",
        "    def setDevice(self , device : torch.device) :\n",
        "        self.encoder = self.encoder.to( device )\n",
        "        self.decoder.setDevice( device )\n",
        "        return\n",
        "\n",
        "\n",
        "    def forward_fit(self, image  , max_lengh = 100):\n",
        "        # print(f\"Passou do Encoder image : { image.shape}\")\n",
        "        img2 = []\n",
        "        for img in image :\n",
        "            img = img.view(1, img.shape[0] , img.shape[1])\n",
        "            img = torch.cat( [img,img,img] , dim = 0 )\n",
        "            # print(f\"img.shape = {img.shape}\")\n",
        "            # print(f\"trasnform : {self.transform_image( img  )[:3].unsqueeze(0).shape }\")\n",
        "            img2 += [self.transform_image( img )[:3].unsqueeze(0) ]\n",
        "        # image = [ self.encoder(self.transform_image( img.view(1 , img.shape[0] , img.shape[1]))[:3].unsqueeze(0) ).view(1,1,-1)     for img in image]\n",
        "        image = [ self.encoder(img).view(1 , 1 , -1) for img in img2 ]\n",
        "        enc   = torch.cat(image , dim = 0 )\n",
        "        # image = self.transform_image(image)[:3].unsqueeze(0)\n",
        "        # print(f\"Passou do Encoder image : {image.shape}\")\n",
        "        # enc = self.encoder(image)\n",
        "        # print(f\"Passou do Encoder enc : {enc.shape}\")\n",
        "        return self.decoder.forward_fit(enc , enc , max_lengh)\n",
        "\n",
        "    def forward(self, image  , max_lengh = 100):\n",
        "        # image = self.transform_image(image)[:3].unsqueeze(0)\n",
        "        # enc = self.encoder(image)\n",
        "\n",
        "        img2 = []\n",
        "        for img in image :\n",
        "            img = img.view(1, img.shape[0] , img.shape[1])\n",
        "            img = torch.cat( [img,img,img] , dim = 0 )\n",
        "            # print(f\"img.shape = {img.shape}\")\n",
        "            # print(f\"trasnform : {self.transform_image( img  )[:3].unsqueeze(0).shape }\")\n",
        "            img2 += [self.transform_image( img )[:3].unsqueeze(0) ]\n",
        "        # image = [ self.encoder(self.transform_image( img.view(1 , img.shape[0] , img.shape[1]))[:3].unsqueeze(0) ).view(1,1,-1)     for img in image]\n",
        "        image = [ self.encoder(img).view(1 , 1 , -1) for img in img2 ]\n",
        "        enc   = torch.cat(image , dim = 0 )\n",
        "\n",
        "        return self.decoder(enc , enc , max_lengh)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oiJQ5ozfmOu5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    max_label_lengh = 9\n",
        "    params = {'batch_size': 30 ,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 8}\n",
        "\n",
        "    path_project = \"/content/drive/Othercomputers/Meu laptop/Dataset_work_space/Torax_Xray\"\n",
        "    image_dir_path = path_project + \"/images/\"\n",
        "    data_intro_path = path_project + \"/Data_Entry_2017.csv\"\n",
        "    label2class_path = path_project + \"/target_dict_label2class.json\"\n",
        "\n",
        "\n",
        "\n",
        "    train_path = path_project + \"/train_val_list.txt\"\n",
        "    test_path  = path_project + \"/test_list.txt\"\n",
        "\n",
        "    train_id = [i.replace(\"\\n\" , \"\") for i in open(train_path , \"r\").readlines() ]\n",
        "    test_id  = [i.replace(\"\\n\" , \"\") for i in open(test_path , \"r\" ).readlines() ]\n",
        "\n",
        "    training_set = dataset_NIH_Chest(train_id , data_intro_path , image_dir_path  , label2class_path , max_label_lengh )\n",
        "    training_loader = DataLoader(training_set, **params)\n",
        "\n",
        "    test_set = dataset_NIH_Chest(test_id , data_intro_path , image_dir_path  , label2class_path , max_label_lengh )\n",
        "    test_loader = DataLoader(test_set, **params)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model   = my_model(torch.device(\"cuda\"))\n",
        "    trainer = Trainer(model , torch.device(\"cuda\") )\n",
        "    model , loss  = trainer.fit(training_loader  , 0.05 , 1 , 1 , test_dataloader = test_loader )\n",
        "\n",
        "    path_2_counter = \"/content/drive/MyDrive/Github_Dir/models_saved.json\"\n",
        "\n",
        "    with open(path_2_counter , \"r\") as arquivo_json:\n",
        "        counter = json.load(arquivo_json)\n",
        "    new_id = int(counter[\"ID_atual\"])\n",
        "\n",
        "    path_2_save = f\"/content/drive/MyDrive/Github_Dir/xRay_model_{new_id}_loss_{loss}.model\"\n",
        "\n",
        "    try:\n",
        "        with open(path_2_save, \"wb\") as arquivo:\n",
        "            pickle.dump(modelo, arquivo)\n",
        "    except FileNotFoundError:\n",
        "        with open(path_2_save, \"xb\") as arquivo:\n",
        "            pickle.dump(modelo, arquivo)\n",
        "\n",
        "    counter[\"ID_atual\"] = f\"{new_id + 1}\"\n",
        "\n",
        "    with open(path_2_counter , \"w\") as arquivo_json:\n",
        "        json.dump(counter , arquivo_json)\n"
      ],
      "metadata": {
        "id": "ecDQjXlifOEl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07296e59-747b-4e4b-ad26-4cc00f5f5590"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "chegou aqui\n",
            "Age atual 0\n",
            " ctd atual 0  samples processados 0\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 1  samples processados 30\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 2  samples processados 60\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 3  samples processados 90\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 4  samples processados 120\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 5  samples processados 150\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 6  samples processados 180\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 7  samples processados 210\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 8  samples processados 240\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 9  samples processados 270\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 10  samples processados 300\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 11  samples processados 330\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 12  samples processados 360\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 13  samples processados 390\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 14  samples processados 420\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 15  samples processados 450\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 16  samples processados 480\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 17  samples processados 510\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 18  samples processados 540\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 19  samples processados 570\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 20  samples processados 600\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 21  samples processados 630\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 22  samples processados 660\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 23  samples processados 690\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 24  samples processados 720\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 25  samples processados 750\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 26  samples processados 780\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 27  samples processados 810\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 28  samples processados 840\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 29  samples processados 870\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 30  samples processados 900\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 31  samples processados 930\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 32  samples processados 960\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 33  samples processados 990\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 34  samples processados 1020\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 35  samples processados 1050\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 36  samples processados 1080\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 37  samples processados 1110\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 38  samples processados 1140\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 39  samples processados 1170\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 40  samples processados 1200\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 41  samples processados 1230\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 42  samples processados 1260\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 43  samples processados 1290\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 44  samples processados 1320\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 45  samples processados 1350\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 46  samples processados 1380\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 47  samples processados 1410\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 48  samples processados 1440\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 49  samples processados 1470\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 50  samples processados 1500\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 51  samples processados 1530\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 52  samples processados 1560\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 53  samples processados 1590\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 54  samples processados 1620\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 55  samples processados 1650\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 56  samples processados 1680\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 57  samples processados 1710\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 58  samples processados 1740\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 59  samples processados 1770\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 60  samples processados 1800\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 61  samples processados 1830\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 62  samples processados 1860\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 63  samples processados 1890\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 64  samples processados 1920\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 65  samples processados 1950\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 66  samples processados 1980\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 67  samples processados 2010\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 68  samples processados 2040\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 69  samples processados 2070\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 70  samples processados 2100\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 71  samples processados 2130\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 72  samples processados 2160\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 73  samples processados 2190\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 74  samples processados 2220\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 75  samples processados 2250\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 76  samples processados 2280\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 77  samples processados 2310\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 78  samples processados 2340\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 79  samples processados 2370\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 80  samples processados 2400\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 81  samples processados 2430\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 82  samples processados 2460\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 83  samples processados 2490\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 84  samples processados 2520\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 85  samples processados 2550\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 86  samples processados 2580\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 87  samples processados 2610\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 88  samples processados 2640\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 89  samples processados 2670\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 90  samples processados 2700\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 91  samples processados 2730\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 92  samples processados 2760\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 93  samples processados 2790\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 94  samples processados 2820\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 95  samples processados 2850\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 96  samples processados 2880\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 97  samples processados 2910\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 98  samples processados 2940\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n",
            " ctd atual 99  samples processados 2970\n",
            "out.shape = torch.Size([30, 16, 10]) , y.shape = torch.Size([30, 10])\n",
            "Pré backward\n",
            "Pós backward\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1726a0fe94be>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mpath_2_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Github_Dir/models_saved.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Torax_Xray-Health-Care/Transformer_Decoder.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataloader, n, maxErro, maxAge, mini_batch_size, lossFunction, lossGraphPath, test_dataloader, out_max_Len, transform)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mctd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Age atual {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;31m#                                                           dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             best_params , lossValue , lossTestList = self.train_Step(dataloader , optimizer  ,\n",
            "\u001b[0;32m/content/Torax_Xray-Health-Care/Transformer_Decoder.py\u001b[0m in \u001b[0;36mtrain_Step\u001b[0;34m(self, dataloader, optimizer, lossFunction, bestLossValue, ctd, lossValue, test_dataloader, out_max_Len, best_params, lossTestList, transform, test_inside_age, test_interval)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mctd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtest_inside_age\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mctd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# A CADA 100 ITERAÇÕES DE MINIBATCH É INICIADA UMA ROTINA DE TESTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mbest_params\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbestLossValue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlossTestList\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__teste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbest_params\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mout_max_Len\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlossTestList\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbestLossValue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Torax_Xray-Health-Care/Transformer_Decoder.py\u001b[0m in \u001b[0;36m__teste\u001b[0;34m(self, test_dataloader, best_params, out_max_Len, lossTestList, bestLossValue, transform)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmax_lengh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_max_Len\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5fc310c9d657>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, max_lengh)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0menc\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmax_lengh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Torax_Xray-Health-Care/Transformer_Decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Enc_values, Enc_keys, max_lengh, force_max_lengh)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mEnc_values\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mEnc_keys\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmax_lengh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mforce_max_lengh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#out shape = batch , seq-len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# sequence = self.BOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"self.BOS.view(1,1,-1)  :  {self.BOS}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Enc_values.shape[0]  :  {Enc_values.shape[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnc_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (generator, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_image_nvjpngl_gpu('/content/drive/Othercomputers/Meu laptop/Dataset_work_space/Torax_Xray/images/00005762_004.png')\n",
        "# load_image_pil_accelerated('/content/drive/Othercomputers/Meu laptop/Dataset_work_space/Torax_Xray/images/00005762_004.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx980fiIY82R",
        "outputId": "88817cd8-d97e-4ff1-83f9-ca42b949ba34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
              "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
              "         [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
              "         ...,\n",
              "         [ 97., 163., 152.,  ...,  44.,  46.,  26.],\n",
              "         [106., 179., 165.,  ...,  47.,  49.,  27.],\n",
              "         [ 53.,  89.,  81.,  ...,  23.,  23.,  13.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install datasets\n"
      ],
      "metadata": {
        "id": "qs59mC7iD6JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import load_dataset\n",
        "\n",
        "# # Carregando o dataset \"alkzar90/NIH-Chest-X-ray-dataset\"\n",
        "# dataset = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", 'image-classification' )\n",
        "\n",
        "# # Acessando os dados de treinamento\n",
        "# train_data = dataset[\"train\"]\n",
        "\n",
        "# # Imprimindo algumas informações\n",
        "# print(f\"Número de exemplos no conjunto de treinamento: {len(train_data)}\")\n",
        "# print(f\"Exemplo de texto: {train_data[0]['text']}\")\n",
        "# print(f\"Rótulo do exemplo: {train_data[0]['label']}\")\n"
      ],
      "metadata": {
        "id": "MEe866skEAwU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}